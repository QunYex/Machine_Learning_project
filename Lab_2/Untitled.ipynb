{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select 190 pics from each class\n",
    "import re\n",
    "import os\n",
    "\n",
    "categories = [item.replace(\"_\"+item.split(\"_\")[-1],\"\") for item in os.listdir(\"/Users/xinqunye/Desktop/2019spring/ml/data/image/mlImage/images\")if not item.startswith(\"#\")]\n",
    "cate_dict = dict.fromkeys(categories)\n",
    "for category in categories:\n",
    "    cate_dict[category] = [animal for animal in os.listdir(\"/Users/xinqunye/Desktop/2019spring/ml/data/image/mlImage/images\") if animal.startswith(category) and not animal.endswith(\"mat\")]\n",
    "save_file = open(\"annotations/new_list.txt\",\"w\")\n",
    "for cate in cate_dict:\n",
    "    for path in cate_dict[cate][0:190]:\n",
    "        save_file.write(path+\"\\n\")\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### #Image CLASS-ID SPECIES BREED ID\n",
    "infos = [item for item in open(\"annotations/list.txt\",'r') if not item.startswith(\"#\")]\n",
    "info_dict = {}\n",
    "for category in categories:\n",
    "    info_dict[category] = {\"class\": \"\",\"species\": \"\",\"breed\":\"\"}\n",
    "    info = [item.replace(\"\\n\",\"\") for item in infos if item.startswith(category)][0].split(\" \")\n",
    "    info_dict[category]['class'] = int(info[-3])\n",
    "    info_dict[category]['species'] = int(info[-2])\n",
    "    info_dict[category]['breed'] = int(info[-1])\n",
    "    \n",
    "info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select 10 class\n",
    "#ID: 1:37 Class ids\n",
    "#SPECIES: 1:Cat 2:Dog\n",
    "#BREED ID: 1-25:Cat 1:12:Dog\n",
    "#All images with 1st letter as captial are cat images\n",
    "#images with small first letter are dog images\n",
    "cats = [item for item in info_dict if info_dict[item]['species'] == 1]\n",
    "dogs = [item for item in info_dict if info_dict[item]['species'] == 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read pic name\n",
    "name = [item.replace(\".jpg\\n\",\"\") for item in open(\"annotations/list_rev.txt\",'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = [item.strip('\\n') for item in open(\"annotations/list_rev.txt\",'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This part we use the matplotlib to read image pixel. Because it's hard to download opencv and configurate the path. Also, matplotlib provides so many packages to calculate the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "%matplotlib inline\n",
    "img = mpimg.imread(\"newImage/basset_hound_144.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "X = np.array()\n",
    "img_plots = []\n",
    "for image_path in file_path:\n",
    "    if image_path.endswith(\"mat\"):\n",
    "        continue\n",
    "    img = mpimg.imread(\"mlImage/images/\"+image_path)\n",
    "    shape = img.shape\n",
    "    #print(shape)\n",
    "    #break\n",
    "    #img_plots.append(plt.imshow(img))\n",
    "    \n",
    "    try:\n",
    "        img = np.reshape(img,(shape[0],shape[1]*shape[2]))\n",
    "    except:\n",
    "        print(image_path)\n",
    "        print(shape)\n",
    "        continue\n",
    "    img = img/255\n",
    "    X.append(img)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img_path = \"/Users/xinqunye/Desktop/2019spring/ml/data/image/mlImage/images/Abyssinian_1.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "    #获取图片的宽和高\n",
    "width,height = img.shape[:2][::-1]\n",
    "    #将图片缩小便于显示观看\n",
    "img_resize = cv2.resize(img,(int(width*0.5),int(height*0.5)),interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(\"img\",img_resize)\n",
    "print(\"img_reisze shape:{}\".format(np.shape(img_resize)))\n",
    "\n",
    "    #将图片转为灰度图\n",
    "img_gray = cv2.cvtColor(img_resize,cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(\"img_gray\",img_gray)\n",
    "print(\"img_gray shape:{}\".format(np.shape(img_gray)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Y = [item.replace(\"_\"+re.findall(r\"[0-9]+\",item)[0]+\".jpg\\n\",\"\") for item in open(\"annotations/list_rev.txt\",'r')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_samples, n_features = X.shape\n",
    "#_, h, w = lfw_people.images.shape\n",
    "n_classes = set([item.strip(\"_\"+item.split(\"_\")[-1]) for item in file_path])\n",
    "len(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(~np.isfinite(X)))\n",
    "print(\"n_samples: {}\".format(n_samples))\n",
    "print(\"n_features: {}\".format(n_features))\n",
    "print(\"n_classes: {}\".format(n_classes))\n",
    "print(\"Original Image Sizes {} by {}\".format(h,w))\n",
    "print (125*94) # the size of the images are the size of the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper plotting function\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.7 * n_col, 2.3 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "plot_gallery(X, names[y], h, w) # defaults to showing a 3 by 6 subset of the faces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using PCA with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X) # fit data and then transform it\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "# print the components\n",
    "\n",
    "print ('pca:', pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cmap = sns.set(style=\"darkgrid\") \n",
    "\n",
    "# this function definition just formats the weights into readable strings\n",
    "# you can skip it without loss of generality to the Data Science content\n",
    "def get_feature_names_from_weights(weights, names):\n",
    "    tmp_array = []\n",
    "    for comp in weights:\n",
    "        tmp_string = ''\n",
    "        for fidx,f in enumerate(names):\n",
    "            if fidx>0 and comp[fidx]>=0:\n",
    "                tmp_string+='+'\n",
    "            tmp_string += '%.2f*%s ' % (comp[fidx],f[:-5])\n",
    "        tmp_array.append(tmp_string)\n",
    "    return tmp_array\n",
    "  \n",
    "plt.style.use('default')\n",
    "# now let's get to the Data Analytics!\n",
    "pca_weight_strings = get_feature_names_from_weights(pca.components_, iris.feature_names) \n",
    "\n",
    "# create some pandas dataframes from the transformed outputs\n",
    "df_pca = pd.DataFrame(X_pca,columns=[pca_weight_strings])\n",
    "\n",
    "from matplotlib.pyplot import scatter\n",
    "\n",
    "# scatter plot the output, with the names created from the weights\n",
    "ax = scatter(X_pca[:,0], X_pca[:,1], c=y, s=(y+2)*10, cmap=cmap)\n",
    "plt.xlabel(pca_weight_strings[0]) \n",
    "plt.ylabel(pca_weight_strings[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
